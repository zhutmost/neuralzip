#===============================================================================
#                     Default Configuration for NeuralZip
#===============================================================================
# *WARNING* Please do NOT modify this file directly.
# If you want to modify configurations, please:
# 1. Create a new YAML file and copy some bellowing options to it.
# 2. Modify these options in your YAML file.
# 3. run main.py with your configuration file in the command line, like this:
#       $ python main.py conf_filepath=path/to/your/config/file
# The options modified in your configuration file will override those in this
# file.
# Moreover, you can also override some options with CLI arguments in this:
#       $ python main.py conf_filepath=... seed=1 optimizer.lr=0.05
#============================ Environment ======================================


# Logs & checkpoints will be dumped in "${REPO_DIR}/${output_dir}/${experiment_name}/vN/".
# The version number "vN" increases automatically.
experiment_name: 'neuralzip-example'
output_dir: 'outputs'

# Evaluate the model on the test set only. If True, the training process will be skipped.
eval: false

# Random seed, should range from 0 to 255. Leave it blank if you want a random one.
seed: 42

# The model to be quantized.
# The created model SHOULD be pretrained, or the quantizer initialization may be incorrect.
model:
  # NeuralZip will try to import ${model.class_name} in order of priority:
  #     1. from torchvision.models import ${model.class_name}
  #     2. import ${model.class_name}
  # Then the ${params} will be passed to the imported object.
  # With the following model settings, NeuralZip will execute:
  #     net = model.resnet_cifar.resnet20(pretrained=true)
  class_name: 'model.resnet_cifar.resnet20'
  params:
    # pretrained: true

# The sub-fields of ${trainer} will be directly passed to the trainer.
# Please visit https://pytorch-lightning.readthedocs.io/en/latest/trainer.html for usage details.
trainer:
  # The distributed mode to run the training. PyTorch-Lightning provides several choices, including
  # "ddp" (i.e. DistributedDataParallel) , "dp" (i.e. DataParallel) and other modes.
  # Please visit https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html for more details.
  accelerator: "ddp"
  # Select GPU (or CPU) devices using ranges, a index list or a string containing comma separated GPU ids.
  # Please visit https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html#select-gpu-devices for more details.
  # Since some bugs caused by PyTorch, if you use "ddp" distributed mode, the GPUs can only be set
  # to a contiguous sequence from 0, like "[0, 1, 2, ...]".
  gpus: ???
  # The maximum number of epochs in training.
  max_epochs: ???
  # More Trainer parameters can be found in its document.

# By default, the checkpoints will be saved to "./checkpoints/" in the output directory.
checkpoint:
  # The path to resume a checkpoint from ${checkpoint.path}. Leave it blank to skip.
  path:

# The dataset, should be implemented as a DataModule. Currently only CIFAR10 & ImageNet is supported.
dataset:
  # Select a dataset. choices: (cifar10, imagenet)
  name: cifar10
  # Path to dataset directory.
  data_dir: '/localhome/fair/Dataset/cifar10'
  # Size of mini-batch per process. That is to say,
  #     1. If "accelerator='ddp'", this field indicates the batch size per device.
  #     2. If "accelerator='dp'", this field indicates the batch size across all devices.
  batch_size: 64
  # Number of data loading workers per process.
  # Do NOT set a very large number if running with the "ddp" accelerator.
  workers: 16

# Quantizers to be injected to the model.
# By default, NeuralZip will inject quantizers into nn.Conv2d and nn.Linear.
# You can override it or append with more types of modules with:
#     net = nz.quantizer_inject(net, cfg.quan, { t.nn.Conv2d: YourConv2dType, t.nn.Conv3d: YourConv3dType })
# Note that the original module will be replaced with your module with the corresponding type:
#     YourModule(original_module, quan_w_fn, quan_a_fn)
# You need to copy parameter values from the original module by yourself. You can refer to neuralzip.func.Conv2d/Linear.
quan:
  act: # (default for activations of all quantized modules)
    # NeuralZip will try to import ${quan.act.class_name} in order of priority:
    #     1. from neuralzip.quantizer import ${quan.act.class_name}
    #     2. import ${quan.act.class_name}
    # With the following settings, NeuralZip will execute:
    #     quan_a_fn = neuralzip.quantizer.LSQQuantizer(bit=3, all_positive=true)
    # Leave ${class_name} blank if you don't want a quantizer.
    class_name: 'LSQQuantizer'
    params:
      # Bit width of quantized activation
      # bit: 3
      # Whether to use symmetric quantization (default: false)
      # symmetric: false
      # Quantize all the numbers to non-negative (default: false)
      # all_positive: true
  weight: # (default for weights all modules)
    class_name: 'LSQQuantizer'
    params:
      # Bit width of quantized weight
      # bit: 3
      # Whether to use symmetric quantization (default: false)
      # symmetric: false
      # Whether to quantize all the numbers to non-negative (default: false)
      # all_positive: false
  excepts:
    # Specify quantized parameters for some certain layers, which will override the above settings.
    # With the following settings, NeuralZip will:
    #     1. skip quantizer injection into the module named "net.fc";
    #     2. quantize activations of module "net.b0.conv1" to 8 bit width, and don't quantize its weights.
    # 'b0.conv1':
    #   act:
    #     params:
    #       bit: 8
    #       all_positive: false
    #   weight:
    #     class_name:
    # fc:
    #   act:
    #     class_name:
    #   weight:
    #     class_name:

# Optimizer to train the model
optimizer:
  # NeuralZip will try to import ${optimizer.class_name} in order of priority:
  #     1. from torchvision.models import ${optimizer.class_name}
  #     2. import ${optimizer.class_name}
  # With the following optimizer settings, NeuralZip will execute:
  #     optimizer = t.optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)
  class_name: 'SGD'
  params:
    # lr: 0.01
    # momentum: 0.9
    # weight_decay: 0.0005

# The learning scheduler for the optimizer.
lr_scheduler:
  # NeuralZip will try to import ${lr_scheduler.class_name} in order of priority:
  #     1. from torchvision.models import ${lr_scheduler.class_name}
  #     2. import ${lr_scheduler.class_name}
  # With the following lr_scheduler settings, NeuralZip will execute:
  #     lr_scheduler = t.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)
  class_name: 'StepLR'
  params:
    # step_size: 30
    # gamma: 0.1
